{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Charging Sessions Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import important libraries needed for the following tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the necessary dataset (charging sessions of EVs) with the data of charging garages in Los Angeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(\"data/charging_sessions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a first sight of the data by displaying the first 5 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>connectionTime</th>\n",
       "      <th>disconnectTime</th>\n",
       "      <th>doneChargingTime</th>\n",
       "      <th>kWhDelivered</th>\n",
       "      <th>sessionID</th>\n",
       "      <th>siteID</th>\n",
       "      <th>spaceID</th>\n",
       "      <th>stationID</th>\n",
       "      <th>timezone</th>\n",
       "      <th>userID</th>\n",
       "      <th>userInputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5e23b149f9af8b5fe4b973cf</td>\n",
       "      <td>2020-01-02 13:08:54+00:00</td>\n",
       "      <td>2020-01-02 19:11:15+00:00</td>\n",
       "      <td>2020-01-02 17:31:35+00:00</td>\n",
       "      <td>25.016</td>\n",
       "      <td>1_1_179_810_2020-01-02 13:08:53.870034</td>\n",
       "      <td>1</td>\n",
       "      <td>AG-3F30</td>\n",
       "      <td>1-1-179-810</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>194.0</td>\n",
       "      <td>[{'WhPerMile': 250, 'kWhRequested': 25.0, 'mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5e23b149f9af8b5fe4b973d0</td>\n",
       "      <td>2020-01-02 13:36:50+00:00</td>\n",
       "      <td>2020-01-02 22:38:21+00:00</td>\n",
       "      <td>2020-01-02 20:18:05+00:00</td>\n",
       "      <td>33.097</td>\n",
       "      <td>1_1_193_825_2020-01-02 13:36:49.599853</td>\n",
       "      <td>1</td>\n",
       "      <td>AG-1F01</td>\n",
       "      <td>1-1-193-825</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>4275.0</td>\n",
       "      <td>[{'WhPerMile': 280, 'kWhRequested': 70.0, 'mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5e23b149f9af8b5fe4b973d1</td>\n",
       "      <td>2020-01-02 13:56:35+00:00</td>\n",
       "      <td>2020-01-03 00:39:22+00:00</td>\n",
       "      <td>2020-01-02 16:35:06+00:00</td>\n",
       "      <td>6.521</td>\n",
       "      <td>1_1_193_829_2020-01-02 13:56:35.214993</td>\n",
       "      <td>1</td>\n",
       "      <td>AG-1F03</td>\n",
       "      <td>1-1-193-829</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>344.0</td>\n",
       "      <td>[{'WhPerMile': 400, 'kWhRequested': 8.0, 'mile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5e23b149f9af8b5fe4b973d2</td>\n",
       "      <td>2020-01-02 13:59:58+00:00</td>\n",
       "      <td>2020-01-02 16:38:39+00:00</td>\n",
       "      <td>2020-01-02 15:18:45+00:00</td>\n",
       "      <td>2.355</td>\n",
       "      <td>1_1_193_820_2020-01-02 13:59:58.309319</td>\n",
       "      <td>1</td>\n",
       "      <td>AG-1F04</td>\n",
       "      <td>1-1-193-820</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>[{'WhPerMile': 400, 'kWhRequested': 8.0, 'mile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5e23b149f9af8b5fe4b973d3</td>\n",
       "      <td>2020-01-02 14:00:01+00:00</td>\n",
       "      <td>2020-01-02 22:08:40+00:00</td>\n",
       "      <td>2020-01-02 18:17:30+00:00</td>\n",
       "      <td>13.375</td>\n",
       "      <td>1_1_193_819_2020-01-02 14:00:00.779967</td>\n",
       "      <td>1</td>\n",
       "      <td>AG-1F06</td>\n",
       "      <td>1-1-193-819</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>334.0</td>\n",
       "      <td>[{'WhPerMile': 400, 'kWhRequested': 16.0, 'mil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                        id             connectionTime  \\\n",
       "0           0  5e23b149f9af8b5fe4b973cf  2020-01-02 13:08:54+00:00   \n",
       "1           1  5e23b149f9af8b5fe4b973d0  2020-01-02 13:36:50+00:00   \n",
       "2           2  5e23b149f9af8b5fe4b973d1  2020-01-02 13:56:35+00:00   \n",
       "3           3  5e23b149f9af8b5fe4b973d2  2020-01-02 13:59:58+00:00   \n",
       "4           4  5e23b149f9af8b5fe4b973d3  2020-01-02 14:00:01+00:00   \n",
       "\n",
       "              disconnectTime           doneChargingTime  kWhDelivered  \\\n",
       "0  2020-01-02 19:11:15+00:00  2020-01-02 17:31:35+00:00        25.016   \n",
       "1  2020-01-02 22:38:21+00:00  2020-01-02 20:18:05+00:00        33.097   \n",
       "2  2020-01-03 00:39:22+00:00  2020-01-02 16:35:06+00:00         6.521   \n",
       "3  2020-01-02 16:38:39+00:00  2020-01-02 15:18:45+00:00         2.355   \n",
       "4  2020-01-02 22:08:40+00:00  2020-01-02 18:17:30+00:00        13.375   \n",
       "\n",
       "                                sessionID  siteID  spaceID    stationID  \\\n",
       "0  1_1_179_810_2020-01-02 13:08:53.870034       1  AG-3F30  1-1-179-810   \n",
       "1  1_1_193_825_2020-01-02 13:36:49.599853       1  AG-1F01  1-1-193-825   \n",
       "2  1_1_193_829_2020-01-02 13:56:35.214993       1  AG-1F03  1-1-193-829   \n",
       "3  1_1_193_820_2020-01-02 13:59:58.309319       1  AG-1F04  1-1-193-820   \n",
       "4  1_1_193_819_2020-01-02 14:00:00.779967       1  AG-1F06  1-1-193-819   \n",
       "\n",
       "              timezone  userID  \\\n",
       "0  America/Los_Angeles   194.0   \n",
       "1  America/Los_Angeles  4275.0   \n",
       "2  America/Los_Angeles   344.0   \n",
       "3  America/Los_Angeles  1117.0   \n",
       "4  America/Los_Angeles   334.0   \n",
       "\n",
       "                                          userInputs  \n",
       "0  [{'WhPerMile': 250, 'kWhRequested': 25.0, 'mil...  \n",
       "1  [{'WhPerMile': 280, 'kWhRequested': 70.0, 'mil...  \n",
       "2  [{'WhPerMile': 400, 'kWhRequested': 8.0, 'mile...  \n",
       "3  [{'WhPerMile': 400, 'kWhRequested': 8.0, 'mile...  \n",
       "4  [{'WhPerMile': 400, 'kWhRequested': 16.0, 'mil...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 66450, columns: 13\n"
     ]
    }
   ],
   "source": [
    "num_rows, num_columns = data_raw.shape\n",
    "print(f\"rows: {num_rows}, columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in the dataset contains 66.450 observation over 13 different variables. Next, we drop duplicates and have closer look at the different datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'connectionTime', 'disconnectTime', 'doneChargingTime', 'kWhDelivered',\n",
    "    'sessionID', 'siteID', 'spaceID', 'stationID', 'timezone', 'userID', 'userInputs'\n",
    "]\n",
    "data_unique = data_raw.drop_duplicates(subset=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Row Datetype\n",
      "0         Unnamed: 0    int64\n",
      "1                 id   object\n",
      "2     connectionTime   object\n",
      "3     disconnectTime   object\n",
      "4   doneChargingTime   object\n",
      "5       kWhDelivered  float64\n",
      "6          sessionID   object\n",
      "7             siteID    int64\n",
      "8            spaceID   object\n",
      "9          stationID   object\n",
      "10          timezone   object\n",
      "11            userID  float64\n",
      "12        userInputs   object\n"
     ]
    }
   ],
   "source": [
    "dtypes_data = data_unique.dtypes.reset_index()\n",
    "dtypes_data.columns = ['Row', 'Datetype']\n",
    "print(dtypes_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert all the data into corresponding data types so that we can use them in the further analysis. \n",
    "The time-related data is given in the UTC time zone, but the garages are in Los Angeles. In order to obtain accurate information about the timestamps, the data must therefore be converted to the corresponding time zone (LosAngeles).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marlo\\AppData\\Local\\Temp\\ipykernel_16412\\2943999569.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_unique['id'] = data_unique['id'].astype(\"string\")\n",
      "C:\\Users\\marlo\\AppData\\Local\\Temp\\ipykernel_16412\\2943999569.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_unique['connectionTime'] = pd.to_datetime(data_unique['connectionTime'], utc=True).dt.tz_convert('America/Los_Angeles').dt.tz_localize(None)\n",
      "C:\\Users\\marlo\\AppData\\Local\\Temp\\ipykernel_16412\\2943999569.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_unique['disconnectTime'] = pd.to_datetime(data_unique['disconnectTime'], utc=True).dt.tz_convert('America/Los_Angeles').dt.tz_localize(None)\n",
      "C:\\Users\\marlo\\AppData\\Local\\Temp\\ipykernel_16412\\2943999569.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_unique['doneChargingTime'] = pd.to_datetime(data_unique['doneChargingTime'], utc=True).dt.tz_convert('America/Los_Angeles').dt.tz_localize(None)\n",
      "C:\\Users\\marlo\\AppData\\Local\\Temp\\ipykernel_16412\\2943999569.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_unique['sessionID'] = data_unique['sessionID'].astype(\"string\")\n",
      "C:\\Users\\marlo\\AppData\\Local\\Temp\\ipykernel_16412\\2943999569.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_unique['siteID'] = data_unique['siteID'].astype(int)\n",
      "C:\\Users\\marlo\\AppData\\Local\\Temp\\ipykernel_16412\\2943999569.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_unique['spaceID'] = data_unique['spaceID'].astype(\"string\")\n",
      "C:\\Users\\marlo\\AppData\\Local\\Temp\\ipykernel_16412\\2943999569.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_unique['stationID'] = data_unique['stationID'].astype(\"string\")\n",
      "C:\\Users\\marlo\\AppData\\Local\\Temp\\ipykernel_16412\\2943999569.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_unique['timezone'] = data_unique['timezone'].astype(\"string\")\n",
      "C:\\Users\\marlo\\AppData\\Local\\Temp\\ipykernel_16412\\2943999569.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_unique['userID'] = data_unique['userID'].astype(\"string\")\n",
      "C:\\Users\\marlo\\AppData\\Local\\Temp\\ipykernel_16412\\2943999569.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_unique['sessionID'] = data_unique['sessionID'].astype(\"string\")\n",
      "C:\\Users\\marlo\\AppData\\Local\\Temp\\ipykernel_16412\\2943999569.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_unique['userInputs'] = data_unique['userInputs'].apply(lambda x: list(x) if isinstance(x, list) else [x])\n"
     ]
    }
   ],
   "source": [
    "data_unique['id'] = data_unique['id'].astype(\"string\")\n",
    "data_unique['connectionTime'] = pd.to_datetime(data_unique['connectionTime'], utc=True).dt.tz_convert('America/Los_Angeles').dt.tz_localize(None)\n",
    "data_unique['disconnectTime'] = pd.to_datetime(data_unique['disconnectTime'], utc=True).dt.tz_convert('America/Los_Angeles').dt.tz_localize(None)\n",
    "data_unique['doneChargingTime'] = pd.to_datetime(data_unique['doneChargingTime'], utc=True).dt.tz_convert('America/Los_Angeles').dt.tz_localize(None)\n",
    "data_unique['sessionID'] = data_unique['sessionID'].astype(\"string\")\n",
    "data_unique['siteID'] = data_unique['siteID'].astype(int)\n",
    "data_unique['spaceID'] = data_unique['spaceID'].astype(\"string\")\n",
    "data_unique['stationID'] = data_unique['stationID'].astype(\"string\")\n",
    "data_unique['timezone'] = data_unique['timezone'].astype(\"string\")\n",
    "data_unique['userID'] = data_unique['userID'].astype(\"string\")\n",
    "data_unique['sessionID'] = data_unique['sessionID'].astype(\"string\")\n",
    "data_unique['userInputs'] = data_unique['userInputs'].apply(lambda x: list(x) if isinstance(x, list) else [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `unnamed` column is presumably an index from the riginal DataFrame and gets transferred into a column when reading the CSV-file. Since our data contains a unique ID for each entry, the unnamed-numbering is not needed and can be deleted. We also delete the id of the respective session (`sessionID`) and loading processes (`id`) because we consider these to be irrelevant for the analysis. Every user has an id and so does every station, so that the individual loading processes can be assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_unique \u001b[38;5;241m=\u001b[39m data_unique\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m data_unique \u001b[38;5;241m=\u001b[39m data_unique\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msessionID\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m data_unique \u001b[38;5;241m=\u001b[39m data_unique\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AA\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5582\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5583\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5584\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5585\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5586\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5587\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5588\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5589\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AA\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AA\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AA\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Unnamed: 0'] not found in axis\""
     ]
    }
   ],
   "source": [
    "data_unique = data_unique.drop('Unnamed: 0', axis=1)\n",
    "data_unique = data_unique.drop('sessionID', axis=1)\n",
    "data_unique = data_unique.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectionTime      datetime64[ns]\n",
      "disconnectTime      datetime64[ns]\n",
      "doneChargingTime    datetime64[ns]\n",
      "kWhDelivered               float64\n",
      "siteID                       int32\n",
      "spaceID             string[python]\n",
      "stationID           string[python]\n",
      "timezone            string[python]\n",
      "userID              string[python]\n",
      "userInputs                  object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the data before dropping NA values from doneChaargingTime\n",
    "data_with_NA = data_unique.copy()\n",
    "\n",
    "# Drop NA from doneChargingTime\n",
    "data_unique.dropna(subset=['doneChargingTime'], inplace=True)\n",
    "\n",
    "# create Table with missing values in doneChargingTime\n",
    "miss_doneChargingTime = data_unique[data_unique['doneChargingTime'].isna()]\n",
    "\n",
    "print(data_unique.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>connectionTime</th>\n",
       "      <th>disconnectTime</th>\n",
       "      <th>doneChargingTime</th>\n",
       "      <th>kWhDelivered</th>\n",
       "      <th>siteID</th>\n",
       "      <th>spaceID</th>\n",
       "      <th>stationID</th>\n",
       "      <th>timezone</th>\n",
       "      <th>userID</th>\n",
       "      <th>userInputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02 05:08:54</td>\n",
       "      <td>2020-01-02 11:11:15</td>\n",
       "      <td>2020-01-02 09:31:35</td>\n",
       "      <td>25.016</td>\n",
       "      <td>1</td>\n",
       "      <td>AG-3F30</td>\n",
       "      <td>1-1-179-810</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>194.0</td>\n",
       "      <td>[[{'WhPerMile': 250, 'kWhRequested': 25.0, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02 05:36:50</td>\n",
       "      <td>2020-01-02 14:38:21</td>\n",
       "      <td>2020-01-02 12:18:05</td>\n",
       "      <td>33.097</td>\n",
       "      <td>1</td>\n",
       "      <td>AG-1F01</td>\n",
       "      <td>1-1-193-825</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>4275.0</td>\n",
       "      <td>[[{'WhPerMile': 280, 'kWhRequested': 70.0, 'mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-02 05:56:35</td>\n",
       "      <td>2020-01-02 16:39:22</td>\n",
       "      <td>2020-01-02 08:35:06</td>\n",
       "      <td>6.521</td>\n",
       "      <td>1</td>\n",
       "      <td>AG-1F03</td>\n",
       "      <td>1-1-193-829</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>344.0</td>\n",
       "      <td>[[{'WhPerMile': 400, 'kWhRequested': 8.0, 'mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-02 05:59:58</td>\n",
       "      <td>2020-01-02 08:38:39</td>\n",
       "      <td>2020-01-02 07:18:45</td>\n",
       "      <td>2.355</td>\n",
       "      <td>1</td>\n",
       "      <td>AG-1F04</td>\n",
       "      <td>1-1-193-820</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>[[{'WhPerMile': 400, 'kWhRequested': 8.0, 'mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-02 06:00:01</td>\n",
       "      <td>2020-01-02 14:08:40</td>\n",
       "      <td>2020-01-02 10:17:30</td>\n",
       "      <td>13.375</td>\n",
       "      <td>1</td>\n",
       "      <td>AG-1F06</td>\n",
       "      <td>1-1-193-819</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>334.0</td>\n",
       "      <td>[[{'WhPerMile': 400, 'kWhRequested': 16.0, 'mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       connectionTime      disconnectTime    doneChargingTime  kWhDelivered  \\\n",
       "0 2020-01-02 05:08:54 2020-01-02 11:11:15 2020-01-02 09:31:35        25.016   \n",
       "1 2020-01-02 05:36:50 2020-01-02 14:38:21 2020-01-02 12:18:05        33.097   \n",
       "2 2020-01-02 05:56:35 2020-01-02 16:39:22 2020-01-02 08:35:06         6.521   \n",
       "3 2020-01-02 05:59:58 2020-01-02 08:38:39 2020-01-02 07:18:45         2.355   \n",
       "4 2020-01-02 06:00:01 2020-01-02 14:08:40 2020-01-02 10:17:30        13.375   \n",
       "\n",
       "   siteID  spaceID    stationID             timezone  userID  \\\n",
       "0       1  AG-3F30  1-1-179-810  America/Los_Angeles   194.0   \n",
       "1       1  AG-1F01  1-1-193-825  America/Los_Angeles  4275.0   \n",
       "2       1  AG-1F03  1-1-193-829  America/Los_Angeles   344.0   \n",
       "3       1  AG-1F04  1-1-193-820  America/Los_Angeles  1117.0   \n",
       "4       1  AG-1F06  1-1-193-819  America/Los_Angeles   334.0   \n",
       "\n",
       "                                          userInputs  \n",
       "0  [[{'WhPerMile': 250, 'kWhRequested': 25.0, 'mi...  \n",
       "1  [[{'WhPerMile': 280, 'kWhRequested': 70.0, 'mi...  \n",
       "2  [[{'WhPerMile': 400, 'kWhRequested': 8.0, 'mil...  \n",
       "3  [[{'WhPerMile': 400, 'kWhRequested': 8.0, 'mil...  \n",
       "4  [[{'WhPerMile': 400, 'kWhRequested': 16.0, 'mi...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 65037 entries, 0 to 65036\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   connectionTime    65037 non-null  datetime64[ns]\n",
      " 1   disconnectTime    65037 non-null  datetime64[ns]\n",
      " 2   doneChargingTime  60950 non-null  datetime64[ns]\n",
      " 3   kWhDelivered      65037 non-null  float64       \n",
      " 4   siteID            65037 non-null  int32         \n",
      " 5   spaceID           65037 non-null  string        \n",
      " 6   stationID         65037 non-null  string        \n",
      " 7   timezone          65037 non-null  string        \n",
      " 8   userID            47822 non-null  string        \n",
      " 9   userInputs        65037 non-null  object        \n",
      "dtypes: datetime64[ns](3), float64(1), int32(1), object(1), string(4)\n",
      "memory usage: 5.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data_unique.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connectionTime          0\n",
      "disconnectTime          0\n",
      "doneChargingTime     4087\n",
      "kWhDelivered            0\n",
      "siteID                  0\n",
      "spaceID                 0\n",
      "stationID               0\n",
      "timezone                0\n",
      "userID              17215\n",
      "userInputs              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values_count = data_unique.isnull().sum()\n",
    "print(missing_values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "connectionTime       0.000000\n",
       "disconnectTime       0.000000\n",
       "doneChargingTime     6.284115\n",
       "kWhDelivered         0.000000\n",
       "siteID               0.000000\n",
       "spaceID              0.000000\n",
       "stationID            0.000000\n",
       "timezone             0.000000\n",
       "userID              26.469548\n",
       "userInputs           0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unique.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.71588480403462"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_unique['doneChargingTime'].dropna())/len(data_unique['doneChargingTime']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the dataframe, you can see that `doneChargingTime` and `userID` have missing values.  \n",
    "\n",
    "The missing values in userID can be explained by the fact that not every garage user is registered; therefore, some accounts are naturally absent. However, the missing entries in `doneChargingTime` appear unusual.\n",
    "\n",
    "Upon closer analysis of the missing entries for the charging time (`miss_doneChargingTime`), we found that all of them have normal values for the attribute `kWhDelivered`, indicating that current flow was indeed present. Removing this data from the dataframe would imply that the charging stations were free at those times, which is inaccurate and would skew predictions. Therefore, we decided to retain this data for now and, if necessary, exclude it during model training and predictions about parking space utilization after charging is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset in two different. One for the station with siteID 1 and one for the station with the siteID 2 for further analysis\n",
    "data_1 = data_unique[data_unique['siteID']==1]\n",
    "data_2 = data_unique[data_unique['siteID']==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Weather Burbank Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weather dataset is also imported and duplicates are removed. Although there are none, we have carried out this step to be on the safe side.  \n",
    "The data was converted to the corresponding data types and the time was adjusted to the los-angeles time zone again.  \n",
    "There is some missing data in this data set for the `temperature` and the `cloud_cover`. However, these are difficult to reproduce and are therefore deleted from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city                       string[python]\n",
      "timestamp                  datetime64[ns]\n",
      "temperature                       float64\n",
      "cloud_cover                       float64\n",
      "cloud_cover_description    string[python]\n",
      "pressure                          float64\n",
      "windspeed                         float64\n",
      "precipitation                     float64\n",
      "felt_temperature                  float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "weather_raw=pd.read_csv(\"data/weather_burbank_airport.csv\")\n",
    "\n",
    "# delete duplicates\n",
    "columns = [\n",
    "    'city', 'timestamp', 'temperature', 'cloud_cover',\n",
    "    'cloud_cover_description', 'pressure', 'windspeed', 'precipitation', 'felt_temperature'\n",
    "]\n",
    "weather_unique = weather_raw.drop_duplicates(subset=columns)\n",
    "\n",
    "#Transform to correct Data Types\n",
    "weather_unique['city']=weather_raw['city'].astype('string')\n",
    "weather_unique['timestamp'] = pd.to_datetime(weather_raw['timestamp'], utc=True).dt.tz_convert('America/Los_Angeles').dt.tz_localize(None)\n",
    "weather_unique['cloud_cover_description']=weather_raw['cloud_cover_description'].astype('string')\n",
    "\n",
    "# drop with missing values\n",
    "weather_unique = weather_unique.dropna(subset=['temperature'])\n",
    "weather_unique = weather_unique.dropna(subset=['cloud_cover'])\n",
    "\n",
    "print(weather_unique.dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
